# With an Ubuntu Image on EC2
# On 20171202, used Ubuntu Server 16.04 LTS (HVM), SSD Volume Type - ami-82f4dae7

# Update apt-get
sudo apt-get update

# Install git
sudo apt-get install git

# Get repp
git clone https://github.com/SidneyPrimas/particle_recognition.git

# Get data (make sure the link is directly to the appropriate zip)
wget https://www.dropbox.com/s/xu0rax6kd7o3nhh/2016_11_27_IrisDB.zip
# Get the original data organized into classes within validation/training. Original image size. 
wget https://www.dropbox.com/s/1knqdxcv590x604/2017_04_IrisDB_resampling.zip

# Get unzip
sudo apt-get install unzip

# Unzip the data folder
unzip ./2016_11_27_IrisDB.zip

# Install Pip (for Python 2.7)
sudo apt-get install python-pip python-dev
# Depending on implementation, install tk (for python GUIs)
# Since many of my script might import these packages, install for consistency. 
sudo apt-get install python-tk

# Install numpy and matplotlib (and other packages, depending on implementation)
pip install numpy
pip install matplotlib
pip install scipy (might need to use: pip --no-cache-dir install scipy)
pip install Pillow

# Setup TF (Python 2.7 on Ubuntu with only CPUs)
# Simple Installation
pip install tensorflow # for Python 2.7 on Ubuntu with only CPUs
# Binary Installation
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
sudo pip install --upgrade $TF_BINARY_URL


# Getting log from EC2
scp -i ./security/sprimas_admin_key-pari_us-east-2.pem ubuntu@ec2-52-14-249-89.us-east-2.compute.amazonaws.com:particle_recognition/log/log_2017-04-18_18\:46\:55 ./log/downsampling_experiment/

# Getting image from EC2
scp -i ./security/sprimas_admin_key-pari_us-east-2.pem ubuntu@ec2-52-14-120-151.us-east-2.compute.amazonaws.com:particle_recognition/data/IrisDB_resampling/Validation/IRIS-NHYAL-CELL/0.jpg ./1p4_NHYAL-CELL_0.jpg

# Getting models from EC2
scp -i ./security/sprimas_admin_key-pari_us-east-2.pem ubuntu@ec2-52-14-180-230.us-east-2.compute.amazonaws.com:particle_recognition/data/particle_model_filters ./6classes_basicGraph_imagesPerClass_imagesPerClass_particle_model_filters 

# Run the Python script (dont' need if I send nothing out to the terminal)
# nohup ensures that you can exit the session and python will still run in the background. 
# stderr and stdout is put into terminal_output.log. Needs to be deleted later as well. 
nohup python ./class_particles/train_iris.py > ./class_particles/data/terminal_output.log &